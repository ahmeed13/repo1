# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset (تأكد من تغيير المسار إلى ملف البيانات الخاص بك)
data = pd.read_csv('custom_dataset.csv')  # تأكد من تغيير المسار إلى ملف البيانات الخاص بك

# Step 1: Analyze the dataset
print(data.info())
print(data.describe())
print(data.isnull().sum())

# Step 2: Preprocessing
# Handling missing values
imputer = SimpleImputer(strategy='mean')
data['numerical_feature'] = imputer.fit_transform(data[['numerical_feature']])

# Encoding categorical variables
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(data[['categorical_feature']]).toarray()
encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['categorical_feature']))
data = pd.concat([data, encoded_df], axis=1)
data.drop('categorical_feature', axis=1, inplace=True)

# Normalization/Standardization
scaler = StandardScaler()
data[['numerical_feature']] = scaler.fit_transform(data[['numerical_feature']])

# Feature selection (example: selecting top 5 features)
selected_features = ['numerical_feature', 'encoded_feature_1', 'encoded_feature_2', 'encoded_feature_3', 'encoded_feature_4']
X = data[selected_features]
y = data['target']

# Step 3: Baseline Model (KNN)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# Step 4: Compare results
print("Accuracy with preprocessing:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
