# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# إنشاء البيانات يدويًا لتتناسب مع متطلبات المشروع
data = pd.DataFrame({
    'numerical_feature_1': [1.2, 2.3, 3.4, 4.5, 5.6, 6.7, 7.8, 8.9, 9.0, 10.1, 11.2, 12.3, 13.4, 14.5, 15.6],
    'numerical_feature_2': [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5, 14.5],
    'categorical_feature': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A'],
    'target': [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0]  # 3 فئات (0, 1, 2)
})

# إضافة قيم مفقودة بشكل عشوائي
data.iloc[1:3, 0] = np.nan  # إضافة قيم مفقودة للعمود الرقمي الأول
data.iloc[5, 2] = np.nan    # إضافة قيم مفقودة للعمود الفئوي

# Step 1: Analyze the dataset
print("Dataset Info:")
print(data.info())
print("\nDataset Description:")
print(data.describe())
print("\nMissing Values:")
print(data.isnull().sum())

# Step 2: Preprocessing
# Handling missing values
imputer_num = SimpleImputer(strategy='mean')  # تعويض القيم المفقودة الرقمية بالمتوسط
data['numerical_feature_1'] = imputer_num.fit_transform(data[['numerical_feature_1']])

imputer_cat = SimpleImputer(strategy='most_frequent')  # تعويض القيم المفقودة الفئوية بالقيمة الأكثر تكرارًا
data['categorical_feature'] = imputer_cat.fit_transform(data[['categorical_feature']]).ravel()

# Encoding categorical variables
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(data[['categorical_feature']]).toarray()
encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['categorical_feature']))
data = pd.concat([data, encoded_df], axis=1)
data.drop('categorical_feature', axis=1, inplace=True)

# Normalization/Standardization
scaler = StandardScaler()
data[['numerical_feature_1', 'numerical_feature_2']] = scaler.fit_transform(data[['numerical_feature_1', 'numerical_feature_2']])

# Feature selection (example: selecting top features)
selected_features = ['numerical_feature_1', 'numerical_feature_2', 'categorical_feature_A', 'categorical_feature_B']
X = data[selected_features]
y = data['target']

# Step 3: Baseline Model (KNN)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# Step 4: Compare results
print("\nAccuracy with preprocessing:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
